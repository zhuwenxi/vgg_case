I0525 12:24:16.814282 75610 caffe.cpp:523] Use CPU.
I0525 12:24:16.986763 75610 cpu_info.cpp:452] Processor speed [MHz]: 1400
I0525 12:24:16.986865 75610 cpu_info.cpp:455] Total number of sockets: 1
I0525 12:24:16.986897 75610 cpu_info.cpp:458] Total number of CPU cores: 68
I0525 12:24:16.986927 75610 cpu_info.cpp:461] Total number of processors: 272
I0525 12:24:16.986958 75610 cpu_info.cpp:464] GPU is used: no
I0525 12:24:16.987004 75610 cpu_info.cpp:467] OpenMP environmental variables are specified: no
I0525 12:24:16.987035 75610 cpu_info.cpp:470] OpenMP thread bind allowed: yes
I0525 12:24:16.987066 75610 cpu_info.cpp:473] Number of OpenMP threads: 68
I0525 12:24:16.987485 75610 net.cpp:752] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0525 12:24:16.987685 75610 net.cpp:752] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0525 12:24:16.987746 75610 net.cpp:752] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
I0525 12:24:16.988960 75610 net.cpp:138] Initializing net from parameters: 
I0525 12:24:16.989105 75610 net.cpp:139] 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 124
  }
  data_param {
    source: "examples/imagenet/ilsvrc12_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
  relu_param {
  }
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
  relu_param {
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
  relu_param {
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
  relu_param {
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
  relu_param {
  }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
  relu_param {
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
  relu_param {
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
  relu_param {
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
  relu_param {
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
  relu_param {
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
  relu_param {
  }
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
  relu_param {
  }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
  relu_param {
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
  relu_param {
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
  relu_param {
  }
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss/loss"
}
I0525 12:24:16.990481 75610 layer_factory.hpp:114] Creating layer data
I0525 12:24:16.994222 75610 net.cpp:183] Creating Layer data
I0525 12:24:16.994359 75610 net.cpp:838] data -> data
I0525 12:24:16.994484 75610 net.cpp:838] data -> label
I0525 12:24:16.999508 75679 db_lmdb.cpp:72] Opened lmdb examples/imagenet/ilsvrc12_train_lmdb
I0525 12:24:17.004695 75610 data_layer.cpp:80] output data size: 64,3,224,224
I0525 12:24:17.045048 75610 net.cpp:267] Setting up data
I0525 12:24:17.045250 75610 net.cpp:274] Top shape: 64 3 224 224 (9633792)
I0525 12:24:17.045366 75610 net.cpp:274] Top shape: 64 (64)
I0525 12:24:17.045423 75610 net.cpp:282] Memory required for data: 38535424
I0525 12:24:17.045512 75610 layer_factory.hpp:114] Creating layer conv1_1
I0525 12:24:17.045673 75610 net.cpp:183] Creating Layer conv1_1
I0525 12:24:17.045780 75610 net.cpp:864] conv1_1 <- data
I0525 12:24:17.045877 75610 net.cpp:838] conv1_1 -> conv1_1
I0525 12:24:17.137344 75610 net.cpp:267] Setting up conv1_1
I0525 12:24:17.137490 75610 net.cpp:274] Top shape: 64 64 224 224 (205520896)
I0525 12:24:17.137534 75610 net.cpp:282] Memory required for data: 860619008
I0525 12:24:17.137660 75610 layer_factory.hpp:114] Creating layer relu1_1
I0525 12:24:17.137786 75610 net.cpp:183] Creating Layer relu1_1
I0525 12:24:17.137862 75610 net.cpp:864] relu1_1 <- conv1_1
I0525 12:24:17.137938 75610 net.cpp:825] relu1_1 -> conv1_1 (in-place)
I0525 12:24:17.138079 75610 net.cpp:267] Setting up relu1_1
I0525 12:24:17.138175 75610 net.cpp:274] Top shape: 64 64 224 224 (205520896)
I0525 12:24:17.138236 75610 net.cpp:282] Memory required for data: 1682702592
I0525 12:24:17.138288 75610 layer_factory.hpp:114] Creating layer conv1_2
I0525 12:24:17.138383 75610 net.cpp:183] Creating Layer conv1_2
I0525 12:24:17.138449 75610 net.cpp:864] conv1_2 <- conv1_1
I0525 12:24:17.138530 75610 net.cpp:838] conv1_2 -> conv1_2
I0525 12:24:19.300945 75610 net.cpp:267] Setting up conv1_2
I0525 12:24:19.301122 75610 net.cpp:274] Top shape: 64 64 224 224 (205520896)
I0525 12:24:19.301174 75610 net.cpp:282] Memory required for data: 2504786176
I0525 12:24:19.301301 75610 layer_factory.hpp:114] Creating layer relu1_2
I0525 12:24:19.301414 75610 net.cpp:183] Creating Layer relu1_2
I0525 12:24:19.301497 75610 net.cpp:864] relu1_2 <- conv1_2
I0525 12:24:19.301589 75610 net.cpp:825] relu1_2 -> conv1_2 (in-place)
I0525 12:24:19.301839 75610 net.cpp:267] Setting up relu1_2
I0525 12:24:19.301929 75610 net.cpp:274] Top shape: 64 64 224 224 (205520896)
I0525 12:24:19.302009 75610 net.cpp:282] Memory required for data: 3326869760
I0525 12:24:19.302069 75610 layer_factory.hpp:114] Creating layer pool1
I0525 12:24:19.302331 75610 net.cpp:183] Creating Layer pool1
I0525 12:24:19.302417 75610 net.cpp:864] pool1 <- conv1_2
I0525 12:24:19.302489 75610 net.cpp:838] pool1 -> pool1
I0525 12:24:19.302628 75610 net.cpp:267] Setting up pool1
I0525 12:24:19.302726 75610 net.cpp:274] Top shape: 64 64 112 112 (51380224)
I0525 12:24:19.302780 75610 net.cpp:282] Memory required for data: 3532390656
I0525 12:24:19.302844 75610 layer_factory.hpp:114] Creating layer conv2_1
I0525 12:24:19.302940 75610 net.cpp:183] Creating Layer conv2_1
I0525 12:24:19.303040 75610 net.cpp:864] conv2_1 <- pool1
I0525 12:24:19.303130 75610 net.cpp:838] conv2_1 -> conv2_1
I0525 12:24:19.844235 75610 net.cpp:267] Setting up conv2_1
I0525 12:24:19.844393 75610 net.cpp:274] Top shape: 64 128 112 112 (102760448)
I0525 12:24:19.844441 75610 net.cpp:282] Memory required for data: 3943432448
I0525 12:24:19.844569 75610 layer_factory.hpp:114] Creating layer relu2_1
I0525 12:24:19.844666 75610 net.cpp:183] Creating Layer relu2_1
I0525 12:24:19.844743 75610 net.cpp:864] relu2_1 <- conv2_1
I0525 12:24:19.844818 75610 net.cpp:825] relu2_1 -> conv2_1 (in-place)
I0525 12:24:19.844911 75610 net.cpp:267] Setting up relu2_1
I0525 12:24:19.845017 75610 net.cpp:274] Top shape: 64 128 112 112 (102760448)
I0525 12:24:19.845072 75610 net.cpp:282] Memory required for data: 4354474240
I0525 12:24:19.845125 75610 layer_factory.hpp:114] Creating layer conv2_2
I0525 12:24:19.845216 75610 net.cpp:183] Creating Layer conv2_2
I0525 12:24:19.845394 75610 net.cpp:864] conv2_2 <- conv2_1
I0525 12:24:19.845490 75610 net.cpp:838] conv2_2 -> conv2_2
I0525 12:24:20.930600 75610 net.cpp:267] Setting up conv2_2
I0525 12:24:20.930752 75610 net.cpp:274] Top shape: 64 128 112 112 (102760448)
I0525 12:24:20.930804 75610 net.cpp:282] Memory required for data: 4765516032
I0525 12:24:20.930918 75610 layer_factory.hpp:114] Creating layer relu2_2
I0525 12:24:20.931040 75610 net.cpp:183] Creating Layer relu2_2
I0525 12:24:20.931123 75610 net.cpp:864] relu2_2 <- conv2_2
I0525 12:24:20.931213 75610 net.cpp:825] relu2_2 -> conv2_2 (in-place)
I0525 12:24:20.931323 75610 net.cpp:267] Setting up relu2_2
I0525 12:24:20.931411 75610 net.cpp:274] Top shape: 64 128 112 112 (102760448)
I0525 12:24:20.931479 75610 net.cpp:282] Memory required for data: 5176557824
I0525 12:24:20.931541 75610 layer_factory.hpp:114] Creating layer pool2
I0525 12:24:20.931782 75610 net.cpp:183] Creating Layer pool2
I0525 12:24:20.931857 75610 net.cpp:864] pool2 <- conv2_2
I0525 12:24:20.931933 75610 net.cpp:838] pool2 -> pool2
I0525 12:24:20.932075 75610 net.cpp:267] Setting up pool2
I0525 12:24:20.932173 75610 net.cpp:274] Top shape: 64 128 56 56 (25690112)
I0525 12:24:20.932229 75610 net.cpp:282] Memory required for data: 5279318272
I0525 12:24:20.932278 75610 layer_factory.hpp:114] Creating layer conv3_1
I0525 12:24:20.932407 75610 net.cpp:183] Creating Layer conv3_1
I0525 12:24:20.932469 75610 net.cpp:864] conv3_1 <- pool2
I0525 12:24:20.932541 75610 net.cpp:838] conv3_1 -> conv3_1
I0525 12:24:21.238145 75610 net.cpp:267] Setting up conv3_1
I0525 12:24:21.238286 75610 net.cpp:274] Top shape: 64 256 56 56 (51380224)
I0525 12:24:21.238322 75610 net.cpp:282] Memory required for data: 5484839168
I0525 12:24:21.238445 75610 layer_factory.hpp:114] Creating layer relu3_1
I0525 12:24:21.238569 75610 net.cpp:183] Creating Layer relu3_1
I0525 12:24:21.238641 75610 net.cpp:864] relu3_1 <- conv3_1
I0525 12:24:21.238713 75610 net.cpp:825] relu3_1 -> conv3_1 (in-place)
I0525 12:24:21.238801 75610 net.cpp:267] Setting up relu3_1
I0525 12:24:21.238873 75610 net.cpp:274] Top shape: 64 256 56 56 (51380224)
I0525 12:24:21.238919 75610 net.cpp:282] Memory required for data: 5690360064
I0525 12:24:21.238998 75610 layer_factory.hpp:114] Creating layer conv3_2
I0525 12:24:21.239105 75610 net.cpp:183] Creating Layer conv3_2
I0525 12:24:21.239169 75610 net.cpp:864] conv3_2 <- conv3_1
I0525 12:24:21.239255 75610 net.cpp:838] conv3_2 -> conv3_2
I0525 12:24:21.847430 75610 net.cpp:267] Setting up conv3_2
I0525 12:24:21.847579 75610 net.cpp:274] Top shape: 64 256 56 56 (51380224)
I0525 12:24:21.847621 75610 net.cpp:282] Memory required for data: 5895880960
I0525 12:24:21.847730 75610 layer_factory.hpp:114] Creating layer relu3_2
I0525 12:24:21.847820 75610 net.cpp:183] Creating Layer relu3_2
I0525 12:24:21.847882 75610 net.cpp:864] relu3_2 <- conv3_2
I0525 12:24:21.848011 75610 net.cpp:825] relu3_2 -> conv3_2 (in-place)
I0525 12:24:21.848121 75610 net.cpp:267] Setting up relu3_2
I0525 12:24:21.848203 75610 net.cpp:274] Top shape: 64 256 56 56 (51380224)
I0525 12:24:21.848253 75610 net.cpp:282] Memory required for data: 6101401856
I0525 12:24:21.848306 75610 layer_factory.hpp:114] Creating layer conv3_3
I0525 12:24:21.848394 75610 net.cpp:183] Creating Layer conv3_3
I0525 12:24:21.848445 75610 net.cpp:864] conv3_3 <- conv3_2
I0525 12:24:21.848529 75610 net.cpp:838] conv3_3 -> conv3_3
I0525 12:24:22.454799 75610 net.cpp:267] Setting up conv3_3
I0525 12:24:22.454963 75610 net.cpp:274] Top shape: 64 256 56 56 (51380224)
I0525 12:24:22.455030 75610 net.cpp:282] Memory required for data: 6306922752
I0525 12:24:22.455119 75610 layer_factory.hpp:114] Creating layer relu3_3
I0525 12:24:22.455247 75610 net.cpp:183] Creating Layer relu3_3
I0525 12:24:22.455302 75610 net.cpp:864] relu3_3 <- conv3_3
I0525 12:24:22.455399 75610 net.cpp:825] relu3_3 -> conv3_3 (in-place)
I0525 12:24:22.455502 75610 net.cpp:267] Setting up relu3_3
I0525 12:24:22.455576 75610 net.cpp:274] Top shape: 64 256 56 56 (51380224)
I0525 12:24:22.455765 75610 net.cpp:282] Memory required for data: 6512443648
I0525 12:24:22.455835 75610 layer_factory.hpp:114] Creating layer pool3
I0525 12:24:22.456044 75610 net.cpp:183] Creating Layer pool3
I0525 12:24:22.456121 75610 net.cpp:864] pool3 <- conv3_3
I0525 12:24:22.456185 75610 net.cpp:838] pool3 -> pool3
I0525 12:24:22.456270 75610 net.cpp:267] Setting up pool3
I0525 12:24:22.456336 75610 net.cpp:274] Top shape: 64 256 28 28 (12845056)
I0525 12:24:22.456380 75610 net.cpp:282] Memory required for data: 6563823872
I0525 12:24:22.456423 75610 layer_factory.hpp:114] Creating layer conv4_1
I0525 12:24:22.456512 75610 net.cpp:183] Creating Layer conv4_1
I0525 12:24:22.456567 75610 net.cpp:864] conv4_1 <- pool3
I0525 12:24:22.456634 75610 net.cpp:838] conv4_1 -> conv4_1
I0525 12:24:22.713068 75610 net.cpp:267] Setting up conv4_1
I0525 12:24:22.713202 75610 net.cpp:274] Top shape: 64 512 28 28 (25690112)
I0525 12:24:22.713237 75610 net.cpp:282] Memory required for data: 6666584320
I0525 12:24:22.713299 75610 layer_factory.hpp:114] Creating layer relu4_1
I0525 12:24:22.713402 75610 net.cpp:183] Creating Layer relu4_1
I0525 12:24:22.713464 75610 net.cpp:864] relu4_1 <- conv4_1
I0525 12:24:22.713527 75610 net.cpp:825] relu4_1 -> conv4_1 (in-place)
I0525 12:24:22.713606 75610 net.cpp:267] Setting up relu4_1
I0525 12:24:22.713670 75610 net.cpp:274] Top shape: 64 512 28 28 (25690112)
I0525 12:24:22.713716 75610 net.cpp:282] Memory required for data: 6769344768
I0525 12:24:22.713757 75610 layer_factory.hpp:114] Creating layer conv4_2
I0525 12:24:22.713860 75610 net.cpp:183] Creating Layer conv4_2
I0525 12:24:22.713914 75610 net.cpp:864] conv4_2 <- conv4_1
I0525 12:24:22.714011 75610 net.cpp:838] conv4_2 -> conv4_2
I0525 12:24:23.216533 75610 net.cpp:267] Setting up conv4_2
I0525 12:24:23.216684 75610 net.cpp:274] Top shape: 64 512 28 28 (25690112)
I0525 12:24:23.216722 75610 net.cpp:282] Memory required for data: 6872105216
I0525 12:24:23.216859 75610 layer_factory.hpp:114] Creating layer relu4_2
I0525 12:24:23.216945 75610 net.cpp:183] Creating Layer relu4_2
I0525 12:24:23.217032 75610 net.cpp:864] relu4_2 <- conv4_2
I0525 12:24:23.217113 75610 net.cpp:825] relu4_2 -> conv4_2 (in-place)
I0525 12:24:23.217200 75610 net.cpp:267] Setting up relu4_2
I0525 12:24:23.217267 75610 net.cpp:274] Top shape: 64 512 28 28 (25690112)
I0525 12:24:23.217314 75610 net.cpp:282] Memory required for data: 6974865664
I0525 12:24:23.217356 75610 layer_factory.hpp:114] Creating layer conv4_3
I0525 12:24:23.217432 75610 net.cpp:183] Creating Layer conv4_3
I0525 12:24:23.217473 75610 net.cpp:864] conv4_3 <- conv4_2
I0525 12:24:23.217546 75610 net.cpp:838] conv4_3 -> conv4_3
I0525 12:24:23.713227 75610 net.cpp:267] Setting up conv4_3
I0525 12:24:23.713362 75610 net.cpp:274] Top shape: 64 512 28 28 (25690112)
I0525 12:24:23.713426 75610 net.cpp:282] Memory required for data: 7077626112
I0525 12:24:23.713491 75610 layer_factory.hpp:114] Creating layer relu4_3
I0525 12:24:23.713548 75610 net.cpp:183] Creating Layer relu4_3
I0525 12:24:23.713582 75610 net.cpp:864] relu4_3 <- conv4_3
I0525 12:24:23.713623 75610 net.cpp:825] relu4_3 -> conv4_3 (in-place)
I0525 12:24:23.713672 75610 net.cpp:267] Setting up relu4_3
I0525 12:24:23.713712 75610 net.cpp:274] Top shape: 64 512 28 28 (25690112)
I0525 12:24:23.713755 75610 net.cpp:282] Memory required for data: 7180386560
I0525 12:24:23.713798 75610 layer_factory.hpp:114] Creating layer pool4
I0525 12:24:23.713961 75610 net.cpp:183] Creating Layer pool4
I0525 12:24:23.714061 75610 net.cpp:864] pool4 <- conv4_3
I0525 12:24:23.714129 75610 net.cpp:838] pool4 -> pool4
I0525 12:24:23.714241 75610 net.cpp:267] Setting up pool4
I0525 12:24:23.714301 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:23.714334 75610 net.cpp:282] Memory required for data: 7206076672
I0525 12:24:23.714370 75610 layer_factory.hpp:114] Creating layer conv5_1
I0525 12:24:23.714428 75610 net.cpp:183] Creating Layer conv5_1
I0525 12:24:23.714457 75610 net.cpp:864] conv5_1 <- pool4
I0525 12:24:23.714512 75610 net.cpp:838] conv5_1 -> conv5_1
I0525 12:24:24.004215 75610 net.cpp:267] Setting up conv5_1
I0525 12:24:24.004349 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:24.004410 75610 net.cpp:282] Memory required for data: 7231766784
I0525 12:24:24.004472 75610 layer_factory.hpp:114] Creating layer relu5_1
I0525 12:24:24.004562 75610 net.cpp:183] Creating Layer relu5_1
I0525 12:24:24.004601 75610 net.cpp:864] relu5_1 <- conv5_1
I0525 12:24:24.004644 75610 net.cpp:825] relu5_1 -> conv5_1 (in-place)
I0525 12:24:24.004698 75610 net.cpp:267] Setting up relu5_1
I0525 12:24:24.004756 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:24.004794 75610 net.cpp:282] Memory required for data: 7257456896
I0525 12:24:24.004837 75610 layer_factory.hpp:114] Creating layer conv5_2
I0525 12:24:24.004910 75610 net.cpp:183] Creating Layer conv5_2
I0525 12:24:24.004947 75610 net.cpp:864] conv5_2 <- conv5_1
I0525 12:24:24.005049 75610 net.cpp:838] conv5_2 -> conv5_2
I0525 12:24:24.301761 75610 net.cpp:267] Setting up conv5_2
I0525 12:24:24.301899 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:24.301930 75610 net.cpp:282] Memory required for data: 7283147008
I0525 12:24:24.302053 75610 layer_factory.hpp:114] Creating layer relu5_2
I0525 12:24:24.302135 75610 net.cpp:183] Creating Layer relu5_2
I0525 12:24:24.302175 75610 net.cpp:864] relu5_2 <- conv5_2
I0525 12:24:24.302217 75610 net.cpp:825] relu5_2 -> conv5_2 (in-place)
I0525 12:24:24.302266 75610 net.cpp:267] Setting up relu5_2
I0525 12:24:24.302304 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:24.302330 75610 net.cpp:282] Memory required for data: 7308837120
I0525 12:24:24.302362 75610 layer_factory.hpp:114] Creating layer conv5_3
I0525 12:24:24.302428 75610 net.cpp:183] Creating Layer conv5_3
I0525 12:24:24.302459 75610 net.cpp:864] conv5_3 <- conv5_2
I0525 12:24:24.302496 75610 net.cpp:838] conv5_3 -> conv5_3
I0525 12:24:24.600122 75610 net.cpp:267] Setting up conv5_3
I0525 12:24:24.600284 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:24.600317 75610 net.cpp:282] Memory required for data: 7334527232
I0525 12:24:24.600412 75610 layer_factory.hpp:114] Creating layer relu5_3
I0525 12:24:24.600468 75610 net.cpp:183] Creating Layer relu5_3
I0525 12:24:24.600507 75610 net.cpp:864] relu5_3 <- conv5_3
I0525 12:24:24.600571 75610 net.cpp:825] relu5_3 -> conv5_3 (in-place)
I0525 12:24:24.600626 75610 net.cpp:267] Setting up relu5_3
I0525 12:24:24.600662 75610 net.cpp:274] Top shape: 64 512 14 14 (6422528)
I0525 12:24:24.600689 75610 net.cpp:282] Memory required for data: 7360217344
I0525 12:24:24.600718 75610 layer_factory.hpp:114] Creating layer pool5
I0525 12:24:24.600837 75610 net.cpp:183] Creating Layer pool5
I0525 12:24:24.600872 75610 net.cpp:864] pool5 <- conv5_3
I0525 12:24:24.600939 75610 net.cpp:838] pool5 -> pool5
I0525 12:24:24.601047 75610 net.cpp:267] Setting up pool5
I0525 12:24:24.601115 75610 net.cpp:274] Top shape: 64 512 7 7 (1605632)
I0525 12:24:24.601157 75610 net.cpp:282] Memory required for data: 7366639872
I0525 12:24:24.601202 75610 layer_factory.hpp:114] Creating layer fc6
I0525 12:24:24.601321 75610 net.cpp:183] Creating Layer fc6
I0525 12:24:24.601366 75610 net.cpp:864] fc6 <- pool5
I0525 12:24:24.601418 75610 net.cpp:838] fc6 -> fc6
I0525 12:24:26.793526 75610 net.cpp:267] Setting up fc6
I0525 12:24:26.793663 75610 net.cpp:274] Top shape: 64 4096 (262144)
I0525 12:24:26.793695 75610 net.cpp:282] Memory required for data: 7367688448
I0525 12:24:26.793781 75610 layer_factory.hpp:114] Creating layer relu6
I0525 12:24:26.793834 75610 net.cpp:183] Creating Layer relu6
I0525 12:24:26.793867 75610 net.cpp:864] relu6 <- fc6
I0525 12:24:26.793931 75610 net.cpp:825] relu6 -> fc6 (in-place)
I0525 12:24:26.794013 75610 net.cpp:267] Setting up relu6
I0525 12:24:26.794056 75610 net.cpp:274] Top shape: 64 4096 (262144)
I0525 12:24:26.794085 75610 net.cpp:282] Memory required for data: 7368737024
I0525 12:24:26.794117 75610 layer_factory.hpp:114] Creating layer drop6
I0525 12:24:26.794179 75610 net.cpp:183] Creating Layer drop6
I0525 12:24:26.794311 75610 net.cpp:864] drop6 <- fc6
I0525 12:24:26.794360 75610 net.cpp:825] drop6 -> fc6 (in-place)
I0525 12:24:26.794425 75610 net.cpp:267] Setting up drop6
I0525 12:24:26.794464 75610 net.cpp:274] Top shape: 64 4096 (262144)
I0525 12:24:26.794490 75610 net.cpp:282] Memory required for data: 7369785600
I0525 12:24:26.794522 75610 layer_factory.hpp:114] Creating layer fc7
I0525 12:24:26.794574 75610 net.cpp:183] Creating Layer fc7
I0525 12:24:26.794602 75610 net.cpp:864] fc7 <- fc6
I0525 12:24:26.794651 75610 net.cpp:838] fc7 -> fc7
I0525 12:24:27.157493 75610 net.cpp:267] Setting up fc7
I0525 12:24:27.157640 75610 net.cpp:274] Top shape: 64 4096 (262144)
I0525 12:24:27.157722 75610 net.cpp:282] Memory required for data: 7370834176
I0525 12:24:27.157797 75610 layer_factory.hpp:114] Creating layer relu7
I0525 12:24:27.157871 75610 net.cpp:183] Creating Layer relu7
I0525 12:24:27.157910 75610 net.cpp:864] relu7 <- fc7
I0525 12:24:27.157958 75610 net.cpp:825] relu7 -> fc7 (in-place)
I0525 12:24:27.158063 75610 net.cpp:267] Setting up relu7
I0525 12:24:27.158118 75610 net.cpp:274] Top shape: 64 4096 (262144)
I0525 12:24:27.158149 75610 net.cpp:282] Memory required for data: 7371882752
I0525 12:24:27.158185 75610 layer_factory.hpp:114] Creating layer drop7
I0525 12:24:27.158259 75610 net.cpp:183] Creating Layer drop7
I0525 12:24:27.158301 75610 net.cpp:864] drop7 <- fc7
I0525 12:24:27.158344 75610 net.cpp:825] drop7 -> fc7 (in-place)
I0525 12:24:27.158397 75610 net.cpp:267] Setting up drop7
I0525 12:24:27.158438 75610 net.cpp:274] Top shape: 64 4096 (262144)
I0525 12:24:27.158468 75610 net.cpp:282] Memory required for data: 7372931328
I0525 12:24:27.158501 75610 layer_factory.hpp:114] Creating layer fc8
I0525 12:24:27.158553 75610 net.cpp:183] Creating Layer fc8
I0525 12:24:27.158582 75610 net.cpp:864] fc8 <- fc7
I0525 12:24:27.158622 75610 net.cpp:838] fc8 -> fc8
I0525 12:24:27.247722 75610 net.cpp:267] Setting up fc8
I0525 12:24:27.247853 75610 net.cpp:274] Top shape: 64 1000 (64000)
I0525 12:24:27.247889 75610 net.cpp:282] Memory required for data: 7373187328
I0525 12:24:27.247943 75610 layer_factory.hpp:114] Creating layer loss
I0525 12:24:27.248106 75610 net.cpp:183] Creating Layer loss
I0525 12:24:27.248170 75610 net.cpp:864] loss <- fc8
I0525 12:24:27.248224 75610 net.cpp:864] loss <- label
I0525 12:24:27.248275 75610 net.cpp:838] loss -> loss/loss
I0525 12:24:27.248358 75610 layer_factory.hpp:114] Creating layer loss
I0525 12:24:27.249529 75610 net.cpp:267] Setting up loss
I0525 12:24:27.249645 75610 net.cpp:274] Top shape: (1)
I0525 12:24:27.249687 75610 net.cpp:277]     with loss weight 1
I0525 12:24:27.249953 75610 net.cpp:282] Memory required for data: 7373187332
I0525 12:24:27.250032 75610 net.cpp:344] loss needs backward computation.
I0525 12:24:27.250074 75610 net.cpp:344] fc8 needs backward computation.
I0525 12:24:27.250109 75610 net.cpp:344] drop7 needs backward computation.
I0525 12:24:27.250143 75610 net.cpp:344] relu7 needs backward computation.
I0525 12:24:27.250174 75610 net.cpp:344] fc7 needs backward computation.
I0525 12:24:27.250208 75610 net.cpp:344] drop6 needs backward computation.
I0525 12:24:27.250242 75610 net.cpp:344] relu6 needs backward computation.
I0525 12:24:27.250274 75610 net.cpp:344] fc6 needs backward computation.
I0525 12:24:27.250308 75610 net.cpp:344] pool5 needs backward computation.
I0525 12:24:27.250344 75610 net.cpp:344] relu5_3 needs backward computation.
I0525 12:24:27.250376 75610 net.cpp:344] conv5_3 needs backward computation.
I0525 12:24:27.250416 75610 net.cpp:344] relu5_2 needs backward computation.
I0525 12:24:27.250452 75610 net.cpp:344] conv5_2 needs backward computation.
I0525 12:24:27.250510 75610 net.cpp:344] relu5_1 needs backward computation.
I0525 12:24:27.250548 75610 net.cpp:344] conv5_1 needs backward computation.
I0525 12:24:27.250587 75610 net.cpp:344] pool4 needs backward computation.
I0525 12:24:27.250624 75610 net.cpp:344] relu4_3 needs backward computation.
I0525 12:24:27.250659 75610 net.cpp:344] conv4_3 needs backward computation.
I0525 12:24:27.250799 75610 net.cpp:344] relu4_2 needs backward computation.
I0525 12:24:27.250847 75610 net.cpp:344] conv4_2 needs backward computation.
I0525 12:24:27.250886 75610 net.cpp:344] relu4_1 needs backward computation.
I0525 12:24:27.250922 75610 net.cpp:344] conv4_1 needs backward computation.
I0525 12:24:27.250959 75610 net.cpp:344] pool3 needs backward computation.
I0525 12:24:27.251027 75610 net.cpp:344] relu3_3 needs backward computation.
I0525 12:24:27.251070 75610 net.cpp:344] conv3_3 needs backward computation.
I0525 12:24:27.251111 75610 net.cpp:344] relu3_2 needs backward computation.
I0525 12:24:27.251149 75610 net.cpp:344] conv3_2 needs backward computation.
I0525 12:24:27.251189 75610 net.cpp:344] relu3_1 needs backward computation.
I0525 12:24:27.251229 75610 net.cpp:344] conv3_1 needs backward computation.
I0525 12:24:27.251269 75610 net.cpp:344] pool2 needs backward computation.
I0525 12:24:27.251312 75610 net.cpp:344] relu2_2 needs backward computation.
I0525 12:24:27.251351 75610 net.cpp:344] conv2_2 needs backward computation.
I0525 12:24:27.251394 75610 net.cpp:344] relu2_1 needs backward computation.
I0525 12:24:27.251433 75610 net.cpp:344] conv2_1 needs backward computation.
I0525 12:24:27.251474 75610 net.cpp:344] pool1 needs backward computation.
I0525 12:24:27.251516 75610 net.cpp:344] relu1_2 needs backward computation.
I0525 12:24:27.251554 75610 net.cpp:344] conv1_2 needs backward computation.
I0525 12:24:27.251598 75610 net.cpp:344] relu1_1 needs backward computation.
I0525 12:24:27.251638 75610 net.cpp:344] conv1_1 needs backward computation.
I0525 12:24:27.251682 75610 net.cpp:346] data does not need backward computation.
I0525 12:24:27.251719 75610 net.cpp:388] This network produces output loss/loss
I0525 12:24:27.251858 75610 net.cpp:424] Network initialization done.
I0525 12:24:27.252611 75610 caffe.cpp:534] Performing Forward
I0525 12:24:30.272680 75610 caffe.cpp:539] Initial loss: 9.07352
I0525 12:24:30.272858 75610 caffe.cpp:541] Performing Backward
I0525 12:24:35.620501 75610 caffe.cpp:550] *** Benchmark begins ***
I0525 12:24:35.620648 75610 caffe.cpp:551] Testing for 10 iterations.
I0525 12:24:40.857462 75610 caffe.cpp:580] Iteration: 1 forward-backward time: 5236 ms.
I0525 12:24:46.010159 75610 caffe.cpp:580] Iteration: 2 forward-backward time: 5152 ms.
I0525 12:24:51.446709 75610 caffe.cpp:580] Iteration: 3 forward-backward time: 5436 ms.
I0525 12:24:56.896904 75610 caffe.cpp:580] Iteration: 4 forward-backward time: 5449 ms.
I0525 12:25:02.279157 75610 caffe.cpp:580] Iteration: 5 forward-backward time: 5382 ms.
I0525 12:25:07.396502 75610 caffe.cpp:580] Iteration: 6 forward-backward time: 5117 ms.
I0525 12:25:12.806563 75610 caffe.cpp:580] Iteration: 7 forward-backward time: 5409 ms.
I0525 12:25:17.966297 75610 caffe.cpp:580] Iteration: 8 forward-backward time: 5159 ms.
I0525 12:25:23.498543 75610 caffe.cpp:580] Iteration: 9 forward-backward time: 5532 ms.
I0525 12:25:28.837239 75610 caffe.cpp:580] Iteration: 10 forward-backward time: 5337 ms.
I0525 12:25:28.837399 75610 caffe.cpp:587] Average time per layer: 
I0525 12:25:28.837502 75610 caffe.cpp:590]       data	forward: 10.53 ms.
I0525 12:25:28.837589 75610 caffe.cpp:594]       data	backward: 0.0046 ms.
I0525 12:25:28.837667 75610 caffe.cpp:590]    conv1_1	forward: 17.1423 ms.
I0525 12:25:28.837738 75610 caffe.cpp:594]    conv1_1	backward: 51.6995 ms.
I0525 12:25:28.837791 75610 caffe.cpp:590]    relu1_1	forward: 13.2819 ms.
I0525 12:25:28.837839 75610 caffe.cpp:594]    relu1_1	backward: 17.0367 ms.
I0525 12:25:28.837883 75610 caffe.cpp:590]    conv1_2	forward: 466.199 ms.
I0525 12:25:28.837929 75610 caffe.cpp:594]    conv1_2	backward: 727.435 ms.
I0525 12:25:28.838002 75610 caffe.cpp:590]    relu1_2	forward: 13.5645 ms.
I0525 12:25:28.838086 75610 caffe.cpp:594]    relu1_2	backward: 17.0094 ms.
I0525 12:25:28.838147 75610 caffe.cpp:590]      pool1	forward: 28.3842 ms.
I0525 12:25:28.838198 75610 caffe.cpp:594]      pool1	backward: 25.8408 ms.
I0525 12:25:28.838248 75610 caffe.cpp:590]    conv2_1	forward: 71.2307 ms.
I0525 12:25:28.838292 75610 caffe.cpp:594]    conv2_1	backward: 157.247 ms.
I0525 12:25:28.838352 75610 caffe.cpp:590]    relu2_1	forward: 6.8837 ms.
I0525 12:25:28.838407 75610 caffe.cpp:594]    relu2_1	backward: 8.2373 ms.
I0525 12:25:28.838469 75610 caffe.cpp:590]    conv2_2	forward: 149.225 ms.
I0525 12:25:28.838523 75610 caffe.cpp:594]    conv2_2	backward: 291.971 ms.
I0525 12:25:28.838570 75610 caffe.cpp:590]    relu2_2	forward: 6.7837 ms.
I0525 12:25:28.838613 75610 caffe.cpp:594]    relu2_2	backward: 8.3335 ms.
I0525 12:25:28.838660 75610 caffe.cpp:590]      pool2	forward: 14.2098 ms.
I0525 12:25:28.838712 75610 caffe.cpp:594]      pool2	backward: 12.3355 ms.
I0525 12:25:28.838762 75610 caffe.cpp:590]    conv3_1	forward: 59.5418 ms.
I0525 12:25:28.838809 75610 caffe.cpp:594]    conv3_1	backward: 123.618 ms.
I0525 12:25:28.838855 75610 caffe.cpp:590]    relu3_1	forward: 3.4897 ms.
I0525 12:25:28.838896 75610 caffe.cpp:594]    relu3_1	backward: 4.3265 ms.
I0525 12:25:28.838940 75610 caffe.cpp:590]    conv3_2	forward: 117.286 ms.
I0525 12:25:28.839030 75610 caffe.cpp:594]    conv3_2	backward: 246.594 ms.
I0525 12:25:28.839084 75610 caffe.cpp:590]    relu3_2	forward: 3.4674 ms.
I0525 12:25:28.839129 75610 caffe.cpp:594]    relu3_2	backward: 4.3348 ms.
I0525 12:25:28.839179 75610 caffe.cpp:590]    conv3_3	forward: 115.014 ms.
I0525 12:25:28.839229 75610 caffe.cpp:594]    conv3_3	backward: 246.332 ms.
I0525 12:25:28.839277 75610 caffe.cpp:590]    relu3_3	forward: 3.4563 ms.
I0525 12:25:28.839319 75610 caffe.cpp:594]    relu3_3	backward: 4.2329 ms.
I0525 12:25:28.839360 75610 caffe.cpp:590]      pool3	forward: 7.206 ms.
I0525 12:25:28.839406 75610 caffe.cpp:594]      pool3	backward: 6.2972 ms.
I0525 12:25:28.839453 75610 caffe.cpp:590]    conv4_1	forward: 43.3145 ms.
I0525 12:25:28.839501 75610 caffe.cpp:594]    conv4_1	backward: 219.236 ms.
I0525 12:25:28.839548 75610 caffe.cpp:590]    relu4_1	forward: 1.8186 ms.
I0525 12:25:28.839589 75610 caffe.cpp:594]    relu4_1	backward: 2.3203 ms.
I0525 12:25:28.839627 75610 caffe.cpp:590]    conv4_2	forward: 87.9958 ms.
I0525 12:25:28.839669 75610 caffe.cpp:594]    conv4_2	backward: 378.401 ms.
I0525 12:25:28.839712 75610 caffe.cpp:590]    relu4_2	forward: 1.7983 ms.
I0525 12:25:28.839756 75610 caffe.cpp:594]    relu4_2	backward: 2.3208 ms.
I0525 12:25:28.839797 75610 caffe.cpp:590]    conv4_3	forward: 88.4097 ms.
I0525 12:25:28.839839 75610 caffe.cpp:594]    conv4_3	backward: 402.796 ms.
I0525 12:25:28.839882 75610 caffe.cpp:590]    relu4_3	forward: 1.8116 ms.
I0525 12:25:28.839923 75610 caffe.cpp:594]    relu4_3	backward: 2.3937 ms.
I0525 12:25:28.839963 75610 caffe.cpp:590]      pool4	forward: 3.7877 ms.
I0525 12:25:28.840030 75610 caffe.cpp:594]      pool4	backward: 3.0318 ms.
I0525 12:25:28.840073 75610 caffe.cpp:590]    conv5_1	forward: 31.7449 ms.
I0525 12:25:28.840117 75610 caffe.cpp:594]    conv5_1	backward: 303.836 ms.
I0525 12:25:28.840163 75610 caffe.cpp:590]    relu5_1	forward: 0.6016 ms.
I0525 12:25:28.840342 75610 caffe.cpp:594]    relu5_1	backward: 0.8142 ms.
I0525 12:25:28.840415 75610 caffe.cpp:590]    conv5_2	forward: 32.9678 ms.
I0525 12:25:28.840461 75610 caffe.cpp:594]    conv5_2	backward: 290.361 ms.
I0525 12:25:28.840505 75610 caffe.cpp:590]    relu5_2	forward: 0.6097 ms.
I0525 12:25:28.840545 75610 caffe.cpp:594]    relu5_2	backward: 0.8337 ms.
I0525 12:25:28.840585 75610 caffe.cpp:590]    conv5_3	forward: 32.5314 ms.
I0525 12:25:28.840628 75610 caffe.cpp:594]    conv5_3	backward: 274.171 ms.
I0525 12:25:28.840672 75610 caffe.cpp:590]    relu5_3	forward: 0.5995 ms.
I0525 12:25:28.840713 75610 caffe.cpp:594]    relu5_3	backward: 0.5461 ms.
I0525 12:25:28.840754 75610 caffe.cpp:590]      pool5	forward: 1.0819 ms.
I0525 12:25:28.840793 75610 caffe.cpp:594]      pool5	backward: 0.8466 ms.
I0525 12:25:28.840836 75610 caffe.cpp:590]        fc6	forward: 12.5761 ms.
I0525 12:25:28.840878 75610 caffe.cpp:594]        fc6	backward: 19.6101 ms.
I0525 12:25:28.840920 75610 caffe.cpp:590]      relu6	forward: 0.0805 ms.
I0525 12:25:28.840962 75610 caffe.cpp:594]      relu6	backward: 0.0483 ms.
I0525 12:25:28.841034 75610 caffe.cpp:590]      drop6	forward: 0.1322 ms.
I0525 12:25:28.841080 75610 caffe.cpp:594]      drop6	backward: 0.0976 ms.
I0525 12:25:28.841122 75610 caffe.cpp:590]        fc7	forward: 3.514 ms.
I0525 12:25:28.841163 75610 caffe.cpp:594]        fc7	backward: 7.1961 ms.
I0525 12:25:28.841204 75610 caffe.cpp:590]      relu7	forward: 0.0806 ms.
I0525 12:25:28.841245 75610 caffe.cpp:594]      relu7	backward: 0.0404 ms.
I0525 12:25:28.841286 75610 caffe.cpp:590]      drop7	forward: 0.1361 ms.
I0525 12:25:28.841328 75610 caffe.cpp:594]      drop7	backward: 0.0799 ms.
I0525 12:25:28.841369 75610 caffe.cpp:590]        fc8	forward: 1.7558 ms.
I0525 12:25:28.841410 75610 caffe.cpp:594]        fc8	backward: 2.2567 ms.
I0525 12:25:28.841450 75610 caffe.cpp:590]       loss	forward: 0.6127 ms.
I0525 12:25:28.841492 75610 caffe.cpp:594]       loss	backward: 0.3167 ms.
I0525 12:25:28.841549 75610 caffe.cpp:600] Average Forward pass: 1455.85 ms.
I0525 12:25:28.841593 75610 caffe.cpp:603] Average Backward pass: 3865.41 ms.
I0525 12:25:28.841639 75610 caffe.cpp:605] Average Forward-Backward: 5322 ms.
I0525 12:25:28.841684 75610 caffe.cpp:608] Total Time: 53220 ms.
I0525 12:25:28.841725 75610 caffe.cpp:609] *** Benchmark ends ***
